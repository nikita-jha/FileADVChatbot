{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitajha/miniconda3/envs/genAI/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chains import RetrievalQA\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from pinecone.grpc import PineconeGRPC\n",
    "from pinecone import ServerlessSpec\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What question asks if the company provides continuous and regular supervisory or management services to securities portfolios? Please include the item as the prefix to the question. (Ex. If it is part a in Item 5, put 5a)\n",
      "Response: The question that asks if the company provides continuous and regular supervisory or management services to securities portfolios is \"F. (1) Do you provide continuous and regular supervisory or management services to securities portfolios?\"\n",
      "--------------------------------------------------\n",
      "Query: What does question N say?\n",
      "Response: Question N asks: \"Are you a public reporting company under Sections 12 or 15(d) of the Securities Exchange Act of 1934?\"\n",
      "--------------------------------------------------\n",
      "Query: What is in part 1 of the criminal disclosure reporting page?\n",
      "Response: Part 1 of the Criminal Disclosure Reporting Page includes the identification of the person(s) or entity(ies) for whom the Disclosure Reporting Page (DRP) is being filed. This could be the advisory firm itself, the firm and one or more of its advisory affiliates, or one or more of the advisory affiliates alone. If the DRP is being filed for an advisory affiliate, the full name of the advisory affiliate is required. If the advisory affiliate has a CRD number, that must be provided. If not, the appropriate box indicating \"non-registered\" should be checked.\n",
      "--------------------------------------------------\n",
      "Query: What does question 3 in Schedule A Directors and Executive Officers section ask for?\n",
      "Response: Question 3 in Schedule A Directors and Executive Officers section asks if the entity has any indirect owners that need to be reported on Schedule B.\n",
      "--------------------------------------------------\n",
      "Query: What question asks what the approximate amount of total regulatory assets under management attributable to non-US persons are? Please include the item as the prefix to the question. (Ex. If it is part a in Item 5, put 5a).\n",
      "Response: The question asking about the approximate amount of total regulatory assets under management attributable to non-US persons is \"Item 5.F.(3) What is the approximate amount of your total regulatory assets under management (reported in Item 5.F.(2)(c) above) attributable to clients who are non-United States persons?\"\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load and process Form ADV PDF\n",
    "pdf_path = \"formADV.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# Split the documents into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# Embed the chunks into vector store\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# Initialize the retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Define the format function\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Initialize GPT-4\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Test cases for specific questions\n",
    "test_queries = [\n",
    "    \"What question asks if the company provides continuous and regular supervisory or management services to securities portfolios? Please include the item as the prefix to the question. (Ex. If it is part a in Item 5, put 5a)\",\n",
    "    \"What does question N say?\",\n",
    "    \"What is in part 1 of the criminal disclosure reporting page?\",\n",
    "    \"What does question 3 in Schedule A Directors and Executive Officers section ask for?\",\n",
    "    \"What question asks what the approximate amount of total regulatory assets under management attributable to non-US persons are? Please include the item as the prefix to the question. (Ex. If it is part a in Item 5, put 5a).\"\n",
    "]\n",
    "\n",
    "# Iterate over test queries\n",
    "for query in test_queries:\n",
    "    print(f\"Query: {query}\")\n",
    "    \n",
    "    # Retrieve relevant document chunks based on the query\n",
    "    context = format_docs(retriever.get_relevant_documents(query))\n",
    "    formatted_prompt = f\"Answer the following based on the context:\\n{context}\\n\\nQuestion: {query}\"\n",
    "    \n",
    "    # Call GPT-4 with the formatted prompt\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    print(f\"Response: {response.content}\\n{'-'*50}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG by itself does not seem to be very good at recognizing the spatial layout of the docuemnt including how the \n",
    "text is related to the numbers and item headings. As such, querying for which specific question in terms of the\n",
    "item and number will not be an effective task with this current approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages in the document: 83\n",
      "Page 1 text:\n",
      "FORM ADV (Paper Version)\n",
      "• UNIFORM APPLICATION FOR INVESTMENT ADVISER\n",
      "REGISTRATION\n",
      "AND\n",
      "• REPORT BY EXEMPT REPORTING ADVISERS\n",
      "PART 1A\n",
      "WARNING:\n",
      "Complete this form truthfully. False statements or omissions may result in\n",
      "denial of your application, revocation of your registration, or criminal\n",
      "prosecution. You must keep this form updated by filing periodic\n",
      "amendments. See Form ADV General Instruction 4.\n",
      "Check the box that indicates what you would like to do (check all that apply):\n",
      "SEC or State Registration:\n",
      "Submit an initial application to register as an investment adviser with the SEC.\n",
      "Submit an initial application to register as an investment adviser with one or more states.\n",
      "Submit an annual updating amendment to your registration for your fiscal year ended\n",
      ".\n",
      "Submit an other-than-annual amendment to your registration.\n",
      "SEC or State Report by Exempt Reporting Advisers:\n",
      "Submit an initial report to the SEC.\n",
      "Submit a report to one or more state securities authorities.\n",
      "Submit an annual updating amendment to your report for your fiscal year ended\n",
      ".\n",
      "Submit an other-than-annual amendment to your report.\n",
      "Submit a final report.\n",
      "Item 1\n",
      "Identifying Information\n",
      "Responses to this Item tell us who you are, where you are doing business, and how we can\n",
      "contact you. If you are filing an umbrella registration, the information in Item 1 should be\n",
      "provided for the filing adviser only. General Instruction 5 provides information to assist you\n",
      "with filing an umbrella registration.\n",
      "A. Your full legal name (if you are a sole proprietor, your last, first, and middle names):\n",
      "B. (1) Name under which you primarily conduct your advisory business, if different from\n",
      "Item 1.A.\n",
      "SEC 1707 (08-22)  File 2 of 5\n",
      "--------------------------------------------------------------------------------\n",
      "Page 2 text:\n",
      "List on Section 1.B. of Schedule D any additional names under which you conduct your\n",
      "advisory business.\n",
      "(2) If you are using this Form ADV to register more than one investment adviser under\n",
      "an umbrella registration, check this box\n",
      "If you check this box, complete a Schedule R for each relying adviser.\n",
      "C. If this filing is reporting a change in your legal name (Item 1.A.) or primary business\n",
      "name (Item 1.B.(1)), enter the new name and specify whether the name change is of\n",
      "your legal name or\n",
      "your primary business name:\n",
      ".\n",
      "D. (1) If you are registered with the SEC as an investment adviser, your SEC file number:\n",
      "801-\n",
      ".\n",
      "(2) If you report to the SEC as an exempt reporting adviser, your SEC file number:\n",
      "802-\n",
      ".\n",
      "(3) If you have one or more Central Index Key numbers assigned by the SEC (“CIK\n",
      "Numbers”), all of your CIK numbers:\n",
      ".\n",
      "E. (1) If you have a number (“CRD Number”) assigned by the FINRA’s CRD system or by\n",
      "the IARD system, your CRD number:\n",
      ".\n",
      "(2) If you have additional CRD Numbers, your additional CRD numbers:\n",
      ".\n",
      "If your firm does not have a CRD number, skip this Item 1.E. Do not provide the CRD\n",
      "number of one of your officers, employees, or affiliates.\n",
      "F. Principal Office and Place of Business\n",
      "(1) Address (do not use a P.O. Box):\n",
      "(number and street)\n",
      "(city)\n",
      "(state/country)\n",
      "(zip +4/postal code)\n",
      "If this address is a private residence, check this box:\n",
      "List on Section 1.F. of Schedule D any office, other than your principal office and place\n",
      "of business, at which you conduct investment advisory business. If you are applying for\n",
      "registration, or are registered, with one or more state securities authorities, you must list\n",
      "2\n",
      "--------------------------------------------------------------------------------\n",
      "Page 3 text:\n",
      "all of your offices in the state or states to which you are applying for registration or with\n",
      "whom you are registered. If you are applying for SEC registration, if you are registered\n",
      "only with the SEC, or if you are reporting to the SEC as an exempt reporting adviser, list\n",
      "the largest twenty-five offices in terms of numbers of employees as of the end of your\n",
      "most recently completed fiscal year.\n",
      "(2) Days of week that you normally conduct business at your principal office and place\n",
      "of business:\n",
      "Monday - Friday\n",
      "Other:\n",
      "Normal business hours at this location:\n",
      "(3) Telephone number at this location:\n",
      "(area code)\n",
      "(telephone number)\n",
      "(4) Facsimile number at this location, if any:\n",
      "(area code)\n",
      "(facsimile number)\n",
      "(5) What is the total number of offices, other than your principal office and place of\n",
      "business, at which you conduct investment advisory business as of the end of your\n",
      "most recently completed fiscal year?\n",
      "G. Mailing address, if different from your principal office and place of business address:\n",
      "(number and street)\n",
      "(city)\n",
      "(state/country)\n",
      "(zip+4/postal code)\n",
      "If this address is a private residence, check this box:\n",
      "H. If you are a sole proprietor, state your full residence address, if different from your\n",
      "principal office and place of business address in Item 1.F.:\n",
      "(number and street)\n",
      "(city)\n",
      "(state/country)\n",
      "(zip+4/postal code)\n",
      "I. Do you have one or more websites or accounts on publicly available social media\n",
      "platforms (including, but not limited to, Twitter, Facebook and LinkedIn)?\n",
      "3\n",
      "--------------------------------------------------------------------------------\n",
      "Page 4 text:\n",
      "Yes\n",
      "No\n",
      "If “yes,” list all firm website addresses and the address for each of the firm’s accounts on\n",
      "publicly available social media platforms on Section 1.I. of Schedule D. If a website\n",
      "address serves as a portal through which to access other information you have published\n",
      "on the web, you may list the portal without listing addresses for all of the other\n",
      "information. You may need to list more than one portal address. Do not provide the\n",
      "addresses of websites or accounts on publicly available social media platforms where\n",
      "you do not control the content. Do not provide the individual electronic mail (e-mail)\n",
      "addresses of employees or the addresses of employee accounts on publicly available\n",
      "social media platforms.\n",
      "J. Chief Compliance Officer\n",
      "(1) Provide the name and contact information of your Chief Compliance Officer. If you\n",
      "are an exempt reporting adviser, you must provide the contact information for your\n",
      "Chief Compliance Officer, if you have one. If not, you must complete Item 1.K.\n",
      "below.\n",
      "(name)\n",
      "(other titles, if any)\n",
      "(area code)\n",
      "(telephone number)\n",
      "(area code)\n",
      "(facsimile number, if any)\n",
      "(number and street)\n",
      "(city)\n",
      "(state/country)\n",
      "(zip+4/postal code)\n",
      "(electronic mail (e-mail) address, if Chief Compliance Officer has one)\n",
      "(2) If your Chief Compliance Officer is compensated or employed by any person other\n",
      "than you, a related person or an investment company registered under the Investment\n",
      "Company Act of 1940 that you advise for providing chief compliance officer\n",
      "services to you, provide the person’s name and IRS Employer Identification Number\n",
      "(if any):\n",
      ".\n",
      "4\n",
      "--------------------------------------------------------------------------------\n",
      "Page 5 text:\n",
      "K. Additional Regulatory Contact Person: If a person other than the Chief Compliance\n",
      "Officer is authorized to receive information and respond to questions about this Form\n",
      "ADV, you may provide that information here.\n",
      "(name)\n",
      "(titles)\n",
      "(area code)\n",
      "(telephone number)\n",
      "(area code)\n",
      "(facsimile number, if any)\n",
      "(number and street)\n",
      "(city)\n",
      "(state/country)\n",
      "(zip+4/postal code)\n",
      "(electronic mail (e-mail) address, if contact person has one)\n",
      "L. Do you maintain some or all of the books and records you are required to keep under\n",
      "Section 204 of the Advisers Act, or similar state law, somewhere other than your\n",
      "principal office and place of business?\n",
      "Yes\n",
      "No\n",
      "If “yes,” complete Section 1.L. of Schedule D.\n",
      "M. Are you registered with a foreign financial regulatory authority?\n",
      "Yes\n",
      "No\n",
      "Answer “no” if you are not registered with a foreign financial regulatory authority, even\n",
      "if you have an affiliate that is registered with a foreign financial regulatory authority. If\n",
      "“yes,” complete Section 1.M. of Schedule D.\n",
      "N. Are you a public reporting company under Sections 12 or 15(d) of the Securities\n",
      "Exchange Act of 1934?\n",
      "Yes\n",
      "No\n",
      "O. Did you have $1 billion or more in assets on the last day of your most recent fiscal year?\n",
      "Yes\n",
      "No\n",
      "If yes, what is the approximate amount of your assets:\n",
      "5\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Load the PDF file\n",
    "pdf_path = \"formADV.pdf\"\n",
    "pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "# Check the total number of pages\n",
    "total_pages = pdf_document.page_count\n",
    "print(f\"Total pages in the document: {total_pages}\")\n",
    "\n",
    "# Loop through the first 5 pages and extract the text\n",
    "for page_num in range(5):\n",
    "    page = pdf_document.load_page(page_num)\n",
    "    page_text = page.get_text(\"text\")  # Extract as plain text\n",
    "    \n",
    "    # Clean the text by removing excessive white spaces\n",
    "    cleaned_text = \"\\n\".join([line.strip() for line in page_text.splitlines() if line.strip()])\n",
    "    \n",
    "    print(f\"Page {page_num + 1} text:\\n{cleaned_text}\\n{'-'*80}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Unstructured Startup API to create structured JSON format from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 15:52:31,199 MainProcess INFO     Created index with configs: {\"input_path\": \"formADV.pdf\", \"recursive\": false}, connection configs: {\"access_config\": \"**********\"}\n",
      "2024-09-19 15:52:31,199 MainProcess INFO     Created download with configs: {\"download_dir\": null}, connection configs: {\"access_config\": \"**********\"}\n",
      "2024-09-19 15:52:31,200 MainProcess INFO     Created partition with configs: {\"strategy\": \"hi_res\", \"ocr_languages\": null, \"encoding\": null, \"additional_partition_args\": {\"split_pdf_page\": true, \"split_pdf_allow_failed\": true, \"split_pdf_concurrency_level\": 15}, \"skip_infer_table_types\": null, \"fields_include\": [\"element_id\", \"text\", \"type\", \"metadata\", \"embeddings\"], \"flatten_metadata\": false, \"metadata_exclude\": [], \"metadata_include\": [], \"partition_endpoint\": \"https://api.unstructuredapp.io/general/v0/general\", \"partition_by_api\": true, \"api_key\": \"*******\", \"hi_res_model_name\": null}\n",
      "2024-09-19 15:52:31,200 MainProcess INFO     Created upload with configs: {\"output_dir\": \"output\"}, connection configs: {\"access_config\": \"**********\"}\n",
      "2024-09-19 15:52:31,200 MainProcess INFO     Running local pipline: index (LocalIndexer) -> download (LocalDownloader) -> partition (hi_res) -> upload (LocalUploader) with configs: {\"reprocess\": false, \"verbose\": false, \"tqdm\": false, \"work_dir\": \"/Users/nikitajha/.cache/unstructured/ingest/pipeline\", \"num_processes\": 2, \"max_connections\": null, \"raise_on_error\": false, \"disable_parallelism\": false, \"preserve_downloads\": false, \"download_only\": false, \"max_docs\": null, \"re_download\": false, \"uncompress\": false, \"otel_endpoint\": null, \"status\": {}}\n",
      "2024-09-19 15:52:31,292 MainProcess INFO     index finished in 3.9e-05s\n",
      "2024-09-19 15:52:31,295 MainProcess INFO     Calling DownloadStep with 1 docs\n",
      "2024-09-19 15:52:31,295 MainProcess INFO     processing content async\n",
      "2024-09-19 15:52:31,295 MainProcess WARNING  async code being run in dedicated thread pool to not conflict with existing event loop: <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "2024-09-19 15:52:31,298 MainProcess INFO     download finished in 0.001613s, attributes: file_id=713e07b89b3b\n",
      "2024-09-19 15:52:31,299 MainProcess INFO     download step finished in 0.003628s\n",
      "2024-09-19 15:52:31,299 MainProcess INFO     Calling PartitionStep with 1 docs\n",
      "2024-09-19 15:52:31,299 MainProcess INFO     processing content async\n",
      "2024-09-19 15:52:31,299 MainProcess WARNING  async code being run in dedicated thread pool to not conflict with existing event loop: <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "2024-09-19 15:52:31,301 MainProcess INFO     partition finished in 0.00121s, attributes: file_id=713e07b89b3b\n",
      "2024-09-19 15:52:31,301 MainProcess INFO     partition step finished in 0.002629s\n",
      "2024-09-19 15:52:31,302 MainProcess INFO     Calling UploadStep with 1 docs\n",
      "2024-09-19 15:52:31,302 MainProcess INFO     processing content across processes\n",
      "2024-09-19 15:52:31,302 MainProcess INFO     processing content serially\n",
      "2024-09-19 15:52:31,302 MainProcess WARNING  async code being run in dedicated thread pool to not conflict with existing event loop: <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "2024-09-19 15:52:31,306 MainProcess INFO     upload finished in 0.003467s, attributes: file_id=713e07b89b3b\n",
      "2024-09-19 15:52:31,307 MainProcess INFO     upload finished in 0.005037s, attributes: file_id=713e07b89b3b\n",
      "2024-09-19 15:52:31,308 MainProcess INFO     upload step finished in 0.005917s\n",
      "2024-09-19 15:52:31,308 MainProcess INFO     ingest process finished in 0.107457s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from unstructured_ingest.v2.pipeline.pipeline import Pipeline\n",
    "from unstructured_ingest.v2.interfaces import ProcessorConfig\n",
    "from unstructured_ingest.v2.processes.connectors.local import (\n",
    "    LocalIndexerConfig,\n",
    "    LocalDownloaderConfig,\n",
    "    LocalConnectionConfig,\n",
    "    LocalUploaderConfig\n",
    ")\n",
    "from unstructured_ingest.v2.processes.partitioner import PartitionerConfig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Pipeline.from_configs(\n",
    "        context=ProcessorConfig(),\n",
    "        indexer_config=LocalIndexerConfig(input_path=os.getenv(\"LOCAL_FILE_INPUT_DIR\")),\n",
    "        downloader_config=LocalDownloaderConfig(),\n",
    "        source_connection_config=LocalConnectionConfig(),\n",
    "        partitioner_config=PartitionerConfig(\n",
    "            partition_by_api=True,\n",
    "            api_key=os.getenv(\"UNSTRUCTURED_API_KEY\"),\n",
    "            partition_endpoint=os.getenv(\"UNSTRUCTURED_API_URL\"),\n",
    "            strategy=\"hi_res\",\n",
    "            additional_partition_args={\n",
    "                \"split_pdf_page\": True,\n",
    "                \"split_pdf_allow_failed\": True,\n",
    "                \"split_pdf_concurrency_level\": 15\n",
    "            }\n",
    "        ),\n",
    "        uploader_config=LocalUploaderConfig(output_dir=os.getenv(\"LOCAL_FILE_OUTPUT_DIR\"))\n",
    "    ).run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'NarrativeText', 'element_id': '124123a904668530d22347dfc82b209e', 'text': 'FORM ADV (Paper Version)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '2b39d8bac3982b03d44ed77ca1a3a19d', 'text': '• UNIFORM APPLICATION FOR INVESTMENT ADVISER REGISTRATION', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'Title', 'element_id': '4fb9aa10432206446703d84cdaf6737b', 'text': 'AND', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '3c82d547122ed90c932dc69638952edf', 'text': '• REPORT BY EXEMPT REPORTING ADVISERS', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '4fb9aa10432206446703d84cdaf6737b', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'Title', 'element_id': 'fac2f8b60258d2a69399de33db8915bb', 'text': 'PART 1A', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'Title', 'element_id': '7b856b12162e29ba5552b57707e52a07', 'text': 'WARNING:', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '11773c73f4a6b80f8e8e513d2358dec5', 'text': 'Complete this form truthfully. False statements or omissions may result in denial of your application, revocation of your registration, or criminal prosecution. You must keep this form updated by filing periodic amendments. See Form ADV General Instruction 4.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '7b856b12162e29ba5552b57707e52a07', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '1b71faddf406f33f55cf6604ec0fbb14', 'text': 'Check the box that indicates what you would like to do (check all that apply):', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '7b856b12162e29ba5552b57707e52a07', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '54d3ed16444f366c6d9db534cbf8c7a4', 'text': 'SEC or State Registration: Submit an initial application to register as an investment adviser with the SEC. Submit an initial application to register as an investment adviser with one or more states. Submit an annual updating amendment to your registration for your fiscal year ended Submit an other-than-annual amendment to your registration. SEC or State Report by Exempt Reporting Advisers: Submit an initial report to the SEC. Submit a report to one or more state securities authorities. Submit an annual updating amendment to your report for your fiscal year ended Submit an other-than-annual amendment to your report. Submit a final report. .', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '7b856b12162e29ba5552b57707e52a07', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'Title', 'element_id': '8b59dc3e7fc14f00f2d76496745a0dff', 'text': 'Item 1 Identifying Information', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'ce84912b5d3ba990213fa2acc62e1af6', 'text': 'Responses to this Item tell us who you are, where you are doing business, and how we can contact you. If you are filing an umbrella registration, the information in Item 1 should be provided for the filing adviser only. General Instruction 5 provides information to assist you with filing an umbrella registration.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '8b59dc3e7fc14f00f2d76496745a0dff', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'd0f974d58d6c8ec49e8448e8c69cebc1', 'text': 'A. Your full legal name (if you are a sole proprietor, your last, first, and middle names):', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '8b59dc3e7fc14f00f2d76496745a0dff', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'fae47f9710e470f73518c0663b9b9a2c', 'text': 'B. (1) Name under which you primarily conduct your advisory business, if different from Item 1.A.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '8b59dc3e7fc14f00f2d76496745a0dff', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'Footer', 'element_id': '3ee84223ecfc156b55a78e596a0d12f6', 'text': 'SEC 1707 (08-22) File 2 of 5', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'UncategorizedText', 'element_id': 'dbefcec0a1437106682383c27defb570', 'text': '.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '9c02d1637b12a1e95c1f6c5667480ee3', 'text': 'List on Section 1.B. of Schedule D any additional names under which you conduct your advisory business.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '45e859a244366e714d42f5df630782a5', 'text': '(2) If you are using this Form ADV to register more than one investment adviser under an umbrella registration, check this box .', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'e6769af73557970f0c6ceb01b46198db', 'text': 'If you check this box, complete a Schedule R for each relying adviser.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '16091799cce9e00f4451bdcd883921b2', 'text': 'C. If this filing is reporting a change in your legal name (Item 1.A.) or primary business name (Item 1.B.(1)), enter the new name and specify whether the name change is of your legal name or', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '61ece5e8397ca4d0c7c1699805d931bd', 'text': 'D. (1) If you are registered with the SEC as an investment adviser, your SEC file number: 801- .', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}]\n",
      "Item 1 Part C is asking if this filing is reporting a change in your legal name (Item 1.A.) or primary business name (Item 1.B.(1)), and if so, to enter the new name and specify whether the name change is of your legal name or primary business name.\n",
      "Item 1, Part A\n"
     ]
    }
   ],
   "source": [
    "# Passing in a small chunk of the structured JSON data to the LLM\n",
    "\n",
    "# Next step is to determine whether to pass in the text iself in a chunked format or create embedding + RAG technique\n",
    "\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load the structured JSON data\n",
    "with open(\"output/formADV.pdf.json\", \"r\") as f:\n",
    "    structured_data = json.load(f)\n",
    "\n",
    "# Extract a small chunk (for example, the first 5 entries)\n",
    "small_chunk = structured_data[:20]\n",
    "\n",
    "print(small_chunk)\n",
    "\n",
    "# Convert the chunk into a string to pass to the LLM\n",
    "json_string_chunk = json.dumps(small_chunk, indent=2)\n",
    "\n",
    "# Initialize GPT-4\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Define a query to ask the LLM\n",
    "query = \"What question is Item 1 Part C asking?\"\n",
    "query2 = \"\"\n",
    "\n",
    "# Combine the query with the chunk of the structured JSON context\n",
    "prompt = f\"Given this structured document data:\\n\\n{json_string_chunk}\\n\\n{query}\"\n",
    "prompt2 = f\"Given this structured document data:\\n\\n{json_string_chunk}\\n\\n{query}\"\n",
    "\n",
    "# Pass the prompt to the LLM\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# Print the response from GPT-4\n",
    "print(response.content)\n",
    "\n",
    "# Define a query for determining which item and part can answer the user's question\n",
    "user_input_question = \"Where do I find information on the adviser's legal name?\"\n",
    "\n",
    "# Structure the prompt\n",
    "prompt = f\"\"\"\n",
    "You are provided with structured data that consists of item numbers and their corresponding parts. \n",
    "Your task is to answer the following question by indicating which item and part number contains the answer. \n",
    "Format your response as 'Item X, Part Y'. If the question is answer by multiple parts of an item, include all \n",
    "parts that are relevant to the question. For example, if the question asks for the number of individual clients of\n",
    "the investment adviser, return 5D(a)(1) and 5D(a)(2). If the question is answered by a single part, only include that part. If \n",
    "the question is not answered by any parts of any items, respond with 'No relevant information found.' \n",
    "\n",
    "Given the structured data:\\n\\n{json_string_chunk}\\n\\nQuestion: {user_input_question}\n",
    "\"\"\"\n",
    "\n",
    "# Pass the prompt to the LLM\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# Print the response from GPT-4\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'NarrativeText', 'element_id': '124123a904668530d22347dfc82b209e', 'text': 'FORM ADV (Paper Version)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '2b39d8bac3982b03d44ed77ca1a3a19d', 'text': '• UNIFORM APPLICATION FOR INVESTMENT ADVISER REGISTRATION', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'Title', 'element_id': '4fb9aa10432206446703d84cdaf6737b', 'text': 'AND', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '3c82d547122ed90c932dc69638952edf', 'text': '• REPORT BY EXEMPT REPORTING ADVISERS', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '4fb9aa10432206446703d84cdaf6737b', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'Title', 'element_id': 'fac2f8b60258d2a69399de33db8915bb', 'text': 'PART 1A', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'Title', 'element_id': '7b856b12162e29ba5552b57707e52a07', 'text': 'WARNING:', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '11773c73f4a6b80f8e8e513d2358dec5', 'text': 'Complete this form truthfully. False statements or omissions may result in denial of your application, revocation of your registration, or criminal prosecution. You must keep this form updated by filing periodic amendments. See Form ADV General Instruction 4.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '7b856b12162e29ba5552b57707e52a07', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '1b71faddf406f33f55cf6604ec0fbb14', 'text': 'Check the box that indicates what you would like to do (check all that apply):', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '7b856b12162e29ba5552b57707e52a07', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '54d3ed16444f366c6d9db534cbf8c7a4', 'text': 'SEC or State Registration: Submit an initial application to register as an investment adviser with the SEC. Submit an initial application to register as an investment adviser with one or more states. Submit an annual updating amendment to your registration for your fiscal year ended Submit an other-than-annual amendment to your registration. SEC or State Report by Exempt Reporting Advisers: Submit an initial report to the SEC. Submit a report to one or more state securities authorities. Submit an annual updating amendment to your report for your fiscal year ended Submit an other-than-annual amendment to your report. Submit a final report. .', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '7b856b12162e29ba5552b57707e52a07', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'Title', 'element_id': '8b59dc3e7fc14f00f2d76496745a0dff', 'text': 'Item 1 Identifying Information', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'ce84912b5d3ba990213fa2acc62e1af6', 'text': 'Responses to this Item tell us who you are, where you are doing business, and how we can contact you. If you are filing an umbrella registration, the information in Item 1 should be provided for the filing adviser only. General Instruction 5 provides information to assist you with filing an umbrella registration.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '8b59dc3e7fc14f00f2d76496745a0dff', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'd0f974d58d6c8ec49e8448e8c69cebc1', 'text': 'A. Your full legal name (if you are a sole proprietor, your last, first, and middle names):', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '8b59dc3e7fc14f00f2d76496745a0dff', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'fae47f9710e470f73518c0663b9b9a2c', 'text': 'B. (1) Name under which you primarily conduct your advisory business, if different from Item 1.A.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'parent_id': '8b59dc3e7fc14f00f2d76496745a0dff', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'Footer', 'element_id': '3ee84223ecfc156b55a78e596a0d12f6', 'text': 'SEC 1707 (08-22) File 2 of 5', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'UncategorizedText', 'element_id': 'dbefcec0a1437106682383c27defb570', 'text': '.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '9c02d1637b12a1e95c1f6c5667480ee3', 'text': 'List on Section 1.B. of Schedule D any additional names under which you conduct your advisory business.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '45e859a244366e714d42f5df630782a5', 'text': '(2) If you are using this Form ADV to register more than one investment adviser under an umbrella registration, check this box .', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'e6769af73557970f0c6ceb01b46198db', 'text': 'If you check this box, complete a Schedule R for each relying adviser.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '16091799cce9e00f4451bdcd883921b2', 'text': 'C. If this filing is reporting a change in your legal name (Item 1.A.) or primary business name (Item 1.B.(1)), enter the new name and specify whether the name change is of your legal name or', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '61ece5e8397ca4d0c7c1699805d931bd', 'text': 'D. (1) If you are registered with the SEC as an investment adviser, your SEC file number: 801- .', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'e99a53c69f904045af8417cc58401944', 'text': '(2) If you report to the SEC as an exempt reporting adviser, your SEC file number: 802- .', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'bf63a2ee06dd24b266e5621beac22f31', 'text': '(3) If you have one or more Central Index Key numbers assigned by the SEC (“CIK Numbers”), all of your CIK numbers: .', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '3f52350a20cf6ed90d9503bb8a5540bb', 'text': 'E. (1) If you have a number (“CRD Number”) assigned by the FINRA’s CRD system or by the IARD system, your CRD number: .', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '80d0b2367876e10be8a4c53610f677ca', 'text': '(2) If you have additional CRD Numbers, your additional CRD numbers:', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '1a94aba297b82f20751aa3af1485374a', 'text': 'If your firm does not have a CRD number, skip this Item 1.E. Do not provide the CRD number of one of your officers, employees, or affiliates.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '7c4b5e77c613f24d06a7e4de554d7af2', 'text': 'F. Principal Office and Place of Business', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '6935b88cec34ba2bab3a18b1675445a0', 'text': '(1) Address (do not use a P.O. Box):', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'ce3e0d292f3a2b8cdfc0051964aee54a', 'text': '(number and street)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'c3ddc2f1f834df3b556aa77411ee83b5', 'text': '(city)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'Title', 'element_id': 'e84383631d38a364f0ee5ab08ff972cb', 'text': '(state/country)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 2, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}]\n",
      "Item 1 Part C is asking if there is a change in the legal name or primary business name of the entity. If there is a change, the new name needs to be entered and specified whether the change is in the legal name or the primary business name.\n",
      "Item 1D(1)\n"
     ]
    }
   ],
   "source": [
    "# Passing in a small chunk of the structured JSON data to the LLM\n",
    "\n",
    "# Next step is to determine whether to pass in the text iself in a chunked format or create embedding + RAG technique\n",
    "\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load the structured JSON data\n",
    "with open(\"output/formADV.pdf.json\", \"r\") as f:\n",
    "    structured_data = json.load(f)\n",
    "\n",
    "# Extract a small chunk (for example, the first 5 entries)\n",
    "small_chunk = structured_data[25:50]\n",
    "\n",
    "print(small_chunk)\n",
    "\n",
    "# Convert the chunk into a string to pass to the LLM\n",
    "json_string_chunk = json.dumps(small_chunk, indent=2)\n",
    "\n",
    "# Initialize GPT-4\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "# Define a query for determining which item and part can answer the user's question\n",
    "user_input_question = \"Where do I find your SEC filing number if you are registered with the SEC as an investment advisor?\"\n",
    "\n",
    "# Structure the prompt\n",
    "prompt = f\"\"\"\n",
    "You are provided with structured data that consists of item numbers and their corresponding parts. \n",
    "Your task is to answer the following question by indicating which item and part number contains the answer. \n",
    "Format your response as 'Item X, Part Y'. If the question is answer by multiple parts of an item, include all \n",
    "parts that are relevant to the question. For example, if the question asks for the number of individual clients of\n",
    "the investment adviser, return 5D(a)(1) and 5D(a)(2). If the question is answered by a single part, only include that part. If \n",
    "the question is not answered by any parts of any items, respond with 'No relevant information found.' \n",
    "\n",
    "Given the structured data:\\n\\n{json_string_chunk}\\n\\nQuestion: {user_input_question}\n",
    "\"\"\"\n",
    "\n",
    "# Pass the prompt to the LLM\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# Print the response from GPT-4\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'NarrativeText', 'element_id': 'f0650c374f397059f034621934405bb8', 'text': '(other titles, if any)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 4, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '851f77730bcea9bad66bcc1818fff09e', 'text': '(area code)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 4, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'd6b6a8cea2b885f171cbf07d39689156', 'text': '(telephone number)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 4, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'c94f311e66c9f75efaa796a7a731aaec', 'text': '(area code) (facsimile number, if any)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 4, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'f3d042192b0cae2e55868b71775ff8ea', 'text': '(area code)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 4, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'c52ee10ab5ada6843a47c8bac97af389', 'text': '(number and street)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 4, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '2b153a71e4d511872e73b9c994e7c2ad', 'text': '(city)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 4, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'b88b25fdb98ebad5566931ead81b0010', 'text': '(state/country)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 4, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '2351066c6dfa851b635ba163241c796e', 'text': '(zip+4/postal code)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 4, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'e09bd9b6eb48911df17836e28dddfe60', 'text': '(electronic mail (e-mail) address, if Chief Compliance Officer has one)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 4, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '3a8393131ef270611c052826d238483a', 'text': '(2) If your Chief Compliance Officer is compensated or employed by any person other than you, a related person or an investment company registered under the Investment Company Act of 1940 that you advise for providing chief compliance officer services to you, provide the person’s name and IRS Employer Identification Number .', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 4, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '8218984d9db5c0e269032f8fa8628888', 'text': '.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 4, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'c9580a63e2e2972a54671af3c50abf15', 'text': '(if any):', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 4, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'UncategorizedText', 'element_id': '84f7b0170cf16562fa65f9fe8774c93c', 'text': '4', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 4, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '069aaaf93c98c4700e45596653f34238', 'text': 'K. Additional Regulatory Contact Person: If a person other than the Chief Compliance Officer is authorized to receive information and respond to questions about this Form ADV, you may provide that information here.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 5, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '79ad3b99afbf8343d6db8189716c8f73', 'text': '(name)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 5, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'e5bc0988953167998eec3d42a01c4e99', 'text': '(titles)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 5, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '0009100ac3f5a854877d4a5106dc6cd0', 'text': '(area code) (telephone number) (area code) (facsimile number, if any) (number and street) (city) (state/country) (zip+4/postal code)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 5, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '82bfe76f77b2e69a4cfb07c0896a6692', 'text': '(electronic mail (e-mail) address, if contact person has one)', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 5, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'd742c078c5af180b8118370e95fa0da8', 'text': 'L. Do you maintain some or all of the books and records you are required to keep under Section 204 of the Advisers Act, or similar state law, somewhere other than your principal office and place of business?', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 5, 'parent_id': 'dd6b4362f9910f8b839257f366d9d241', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'Title', 'element_id': '339c35e1d6f0ff6e308dd51c4f1b8893', 'text': 'Yes', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 5, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'Title', 'element_id': '05e05c6d893acb710249cab99918d13a', 'text': 'No', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 5, 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '10db991558473975c250c92192cdd7bd', 'text': 'If “yes,” complete Section 1.L. of Schedule D.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 5, 'parent_id': '05e05c6d893acb710249cab99918d13a', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': '5d1c6b69770354f55db63e027949980c', 'text': 'M. Are you registered with a foreign financial regulatory authority? Yes No', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 5, 'parent_id': '05e05c6d893acb710249cab99918d13a', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}, {'type': 'NarrativeText', 'element_id': 'e4b4589dcc9bdeb626cedfd27a55877b', 'text': 'Answer “no” if you are not registered with a foreign financial regulatory authority, even if you have an affiliate that is registered with a foreign financial regulatory authority. If “yes,” complete Section 1.M. of Schedule D.', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 5, 'parent_id': '05e05c6d893acb710249cab99918d13a', 'filename': 'formADV.pdf', 'data_source': {'url': None, 'version': None, 'record_locator': {'path': '/Users/nikitajha/Documents/NikitaFinal/Coding Projects/SEC/formADV.pdf'}, 'date_created': '1725737463.6450179', 'date_modified': '1725737463.6473238', 'date_processed': '1725931022.635649', 'permissions_data': [{'mode': 33188}], 'filesize_bytes': 767857}}}]\n",
      "Item M\n"
     ]
    }
   ],
   "source": [
    "# Passing in a small chunk of the structured JSON data to the LLM\n",
    "\n",
    "# Next step is to determine whether to pass in the text iself in a chunked format or create embedding + RAG technique\n",
    "\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load the structured JSON data\n",
    "with open(\"output/formADV.pdf.json\", \"r\") as f:\n",
    "    structured_data = json.load(f)\n",
    "\n",
    "# Extract a small chunk (for example, the first 5 entries)\n",
    "small_chunk = structured_data[50:75]\n",
    "\n",
    "print(small_chunk)\n",
    "\n",
    "# Convert the chunk into a string to pass to the LLM\n",
    "json_string_chunk = json.dumps(small_chunk, indent=2)\n",
    "\n",
    "# Initialize GPT-4\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "# Define a query for determining which item and part can answer the user's question\n",
    "user_input_question = \"Which item and question asks if you are registered with a foreign financial regulatory authority?\"\n",
    "\n",
    "# Structure the prompt\n",
    "prompt = f\"\"\"\n",
    "You are provided with structured data that consists of item numbers and their corresponding parts. \n",
    "Your task is to answer the following question by indicating which item and part number contains the answer. \n",
    "Format your response as 'Item X, Part Y'. If the question is answer by multiple parts of an item, include all \n",
    "parts that are relevant to the question. For example, if the question asks for the number of individual clients of\n",
    "the investment adviser, return 5D(a)(1) and 5D(a)(2). If the question is answered by a single part, only include that part. If \n",
    "the question is not answered by any parts of any items, respond with 'No relevant information found.' \n",
    "\n",
    "Given the structured data:\\n\\n{json_string_chunk}\\n\\nQuestion: {user_input_question}\n",
    "\"\"\"\n",
    "\n",
    "# Pass the prompt to the LLM\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# Print the response from GPT-4\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What question asks for which days of week that you normally conduct business at your principal office and place of business?\n",
      "Response: The question that asks for which days of week that you normally conduct business at your principal office and place of business is in part (2).\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load and process structured JSON data\n",
    "with open(\"output/refinedOutput.json\", \"r\") as f:\n",
    "    structured_data = json.load(f)\n",
    "\n",
    "# Convert JSON content to a format suitable for embedding\n",
    "def extract_text_from_json(data):\n",
    "    return \"\\n\".join([str(item) for item in data])\n",
    "\n",
    "# Extract text from the structured JSON data\n",
    "json_string_chunk = extract_text_from_json(structured_data)\n",
    "\n",
    "# Split the text into smaller chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_text(json_string_chunk)\n",
    "\n",
    "# Embed the chunks into the vector store\n",
    "vectorstore = Chroma.from_texts(texts=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# Initialize the retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Initialize GPT-4\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Define the instructions and user query\n",
    "instructions = \"\"\"\n",
    "You are provided with structured data that consists of item numbers and their corresponding parts. \n",
    "Your task is to answer the following question by indicating which item and part number contains the answer. \n",
    "For example, if the question asks for the number of individual clients of the investment adviser, \n",
    "return 5D(a)(1) and 5D(a)(2). If the question is answered by a single part, only include that part. \n",
    "If the question is not answered by any parts of any items, respond with 'No relevant information found.'\n",
    "\"\"\"\n",
    "\n",
    "# Define the user queries (test cases)\n",
    "test_queries = [\n",
    "    \"What question asks for which days of week that you normally conduct business at your principal office and place of business?\"\n",
    "]\n",
    "\n",
    "# Iterate over the test queries and run them\n",
    "for query in test_queries:\n",
    "    print(f\"Query: {query}\")\n",
    "    \n",
    "    # Retrieve relevant document chunks based on the query\n",
    "    context = format_docs(retriever.get_relevant_documents(query))\n",
    "    \n",
    "    # Combine instructions with the query for the prompt\n",
    "    formatted_prompt = f\"{instructions}\\n\\nContext: {context}\\n\\nQuestion: {query}\"\n",
    "    \n",
    "    # Call GPT-4 with the formatted prompt\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    \n",
    "    # Print the response\n",
    "    print(f\"Response: {response.content}\\n{'-'*50}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OFFICIALLY GIVING UP ON RAG\n",
    "\n",
    "PDF to Image Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-A9OSW8msvM8MCphpJdtHztqorrzrP', 'object': 'chat.completion', 'created': 1726802336, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'The images contain a document labeled \"FORM ADV (Paper Version)\" which is a form used for registration by investment advisers. It includes sections for:\\n\\n1. **General Information**: Instructions and warnings about the form\\'s completion.\\n2. **Application Options**: Checkboxes for choosing between initial applications, amendments, or reports for both SEC or state registration and exemption reporting advisers.\\n3. **Identifying Information**: Sections for the applicant\\'s legal name, business name, SEC file number, and addresses.\\n4. **Additional Requirements**: Information on where to list additional names and changes in legal or business names.\\n\\nThe document outlines essential details that investment advisers need to provide to comply with regulatory requirements.', 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51015, 'completion_tokens': 140, 'total_tokens': 51155, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'system_fingerprint': 'fp_e9627b5346'}\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# OpenAI API Key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Convert PDF to images\n",
    "pdf_path = 'formADV.pdf'\n",
    "images = convert_from_path(pdf_path, first_page=1, last_page=26)\n",
    "\n",
    "# Function to encode the image in base64\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Save and encode images\n",
    "encoded_images = []\n",
    "for i, image in enumerate(images):\n",
    "    image_path = f'page_{i+1}.png'\n",
    "    image.save(image_path, 'PNG')\n",
    "    \n",
    "    # Encode each image as base64\n",
    "    base64_image = encode_image(image_path)\n",
    "    encoded_images.append(base64_image)\n",
    "\n",
    "# Create payload with base64 images\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "# Example with two images (you can scale this up for more images)\n",
    "payload = {\n",
    "  \"model\": \"gpt-4o-mini\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What’s in these images?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\"url\": f\"data:image/png;base64,{encoded_images[0]}\"}\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\"url\": f\"data:image/png;base64,{encoded_images[1]}\"}\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "# Send the request to OpenAI API\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "# Print the response\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images you provided are pages from Form ADV, specifically a paper version of the Uniform Application for Investment Adviser Registration and Report by Exempt Reporting Advisers. This form is used by individuals and firms to register as investment advisers with the Securities and Exchange Commission (SEC) or relevant state authorities. \n",
      "\n",
      "Key sections include:\n",
      "\n",
      "1. **Part 1A** - Notifies the applicant about the importance of truthful information and outlines different registration options.\n",
      "2. **Item 1** - Contains identifying information prompts, including legal names, business names, SEC file numbers, and addresses.\n",
      "3. **State Registration and Reporting Requirements** - Details on submitting initial applications, updates, or amendments relevant to investment advisers.\n",
      "\n",
      "Overall, the form collects essential information for regulatory compliance regarding financial advisory services.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create payload with base64 images\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "# Example with two images (you can scale this up for more images)\n",
    "payload = {\n",
    "  \"model\": \"gpt-4o-mini\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What’s in these images?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\"url\": f\"data:image/png;base64,{encoded_images[0]}\"}\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\"url\": f\"data:image/png;base64,{encoded_images[1]}\"}\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "# Assuming you already have the response\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "# Parse the response to JSON\n",
    "response_json = response.json()\n",
    "\n",
    "# Extract the message content\n",
    "message_content = response_json['choices'][0]['message']['content']\n",
    "print(message_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question asks for your SEC filing number if you are registered with the SEC as an investment adviser. The relevant item and part numbers containing this information are:\n",
      "\n",
      "**Item 1, Part D(1)**.\n"
     ]
    }
   ],
   "source": [
    "# Create payload with base64 images\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "# Define the instructions for relevant items, parts, etc.\n",
    "instructions = \"\"\"\n",
    "You are provided with structured data that consists of item numbers and their corresponding parts. \n",
    "Your task is to answer the following question by indicating which item and part number contains the answer. \n",
    "For example, if the question asks for the number of individual clients of the investment adviser, \n",
    "return 5D(a)(1) and 5D(a)(2). If the question is answered by a single part, only include that part. \n",
    "If the question is not answered by any parts of any items, respond with 'No relevant information found.\n",
    "\"\"\"\n",
    "\n",
    "# Example with two images (you can scale this up for more images)\n",
    "payload = {\n",
    "  \"model\": \"gpt-4o-mini\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": f\"{instructions} Which questions asks for your SEC filing number if you are registered with the SEC as an investment advisor?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\"url\": f\"data:image/png;base64,{encoded_images[0]}\"}\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\"url\": f\"data:image/png;base64,{encoded_images[1]}\"}\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "# Send the request to OpenAI API\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "# Parse the response to JSON\n",
    "response_json = response.json()\n",
    "\n",
    "# Extract the message content\n",
    "message_content = response_json['choices'][0]['message']['content']\n",
    "print(message_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitajha/miniconda3/envs/localgpt-vision/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  9.41it/s]\n",
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing file: images/page_2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 0 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 1 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 2 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 3 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 4 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_7.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 5 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 6 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_19.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 7 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_25.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 8 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_24.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 9 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_18.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 10 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_26.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 11 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_23.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 12 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_22.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 13 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_20.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 14 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_21.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 15 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 16 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_11.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 17 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_13.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 18 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_12.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 19 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_16.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 20 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_17.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 21 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_15.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 22 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_14.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 23 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_8.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 24 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_9.png\n",
      "Added page 1 of document 25 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing complete. Images indexed in image_index.\n"
     ]
    }
   ],
   "source": [
    "from byaldi import RAGMultiModalModel\n",
    "\n",
    "# Step 1: Initialize the ColPali model\n",
    "def initialize_colpali_model():\n",
    "    model = RAGMultiModalModel.from_pretrained(\"vidore/colpali\")\n",
    "    return model\n",
    "\n",
    "# Step 2: Index your images\n",
    "def index_images(image_directory, index_name=\"image_index\"):\n",
    "    # Initialize the model\n",
    "    model = initialize_colpali_model()\n",
    "\n",
    "    # Index the images in the specified directory\n",
    "    model.index(\n",
    "        input_path=image_directory,  # Path to your directory containing images\n",
    "        index_name=index_name,       # Name for your index\n",
    "        store_collection_with_index=False,  # You can store the indexed data for later retrieval\n",
    "        overwrite=True               # Overwrite existing index if any\n",
    "    )\n",
    "\n",
    "    print(f\"Indexing complete. Images indexed in {index_name}.\")\n",
    "\n",
    "# Example usage:\n",
    "index_images(\"images/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.42it/s]\n",
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overwrite is on. Deleting existing index image_index to build a new one.\n",
      "Indexing file: images/page_2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 0 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_3.png\n",
      "Added page 1 of document 1 to index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 2 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 3 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 4 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_7.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 5 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 6 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_19.png\n",
      "Added page 1 of document 7 to index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_25.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 8 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_24.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 9 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_18.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 10 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_26.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 11 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_23.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 12 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_22.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 13 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_20.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 14 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_21.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 15 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 16 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_11.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 17 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_13.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 18 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_12.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 19 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_16.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 20 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_17.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 21 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_15.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 22 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_14.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 23 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_8.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 24 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_9.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 25 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Index exported to .byaldi/image_index\n",
      "Top 5 results for query 'What does Item 1 part A ask?':\n",
      "Doc ID: 16, Page: 1, Score: 19.125\n",
      "Doc ID: 2, Page: 1, Score: 19.125\n",
      "Doc ID: 15, Page: 1, Score: 18.875\n",
      "Doc ID: 22, Page: 1, Score: 18.75\n",
      "Doc ID: 21, Page: 1, Score: 18.75\n"
     ]
    }
   ],
   "source": [
    "from byaldi import RAGMultiModalModel\n",
    "\n",
    "# Step 1: Initialize the ColPali model and index the images (if needed)\n",
    "def initialize_model_and_index(image_directory, index_name=\"image_index\"):\n",
    "    # Initialize the model\n",
    "    model = RAGMultiModalModel.from_pretrained(\"vidore/colpali\")\n",
    "    \n",
    "    # Index the images if the index does not already exist\n",
    "    model.index(\n",
    "        input_path=image_directory,\n",
    "        index_name=index_name,\n",
    "        store_collection_with_index=False,\n",
    "        overwrite=True  # Set to False to avoid overwriting an existing index\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Step 2: Search for relevant images (reusing the same model instance)\n",
    "def search_images(model, query, top_k=5):\n",
    "    # Perform the search using the internal index\n",
    "    results = model.search(query, k=top_k)\n",
    "\n",
    "    # Step 3: Display the results\n",
    "    print(f\"Top {top_k} results for query '{query}':\")\n",
    "    for result in results:\n",
    "        print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")\n",
    "\n",
    "# Example usage:\n",
    "image_directory = \"images/\"\n",
    "model = initialize_model_and_index(image_directory, \"image_index\")  # Initialize model and index images\n",
    "search_images(model, \"What does Item 1 part A ask?\", top_k=5)  # Reuse the model for each query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.51it/s]\n",
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overwrite is on. Deleting existing index image_index to build a new one.\n",
      "Indexing file: images/page_2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 0 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 1 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 2 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 3 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 4 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_7.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 5 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 6 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_19.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 7 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_25.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 8 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_24.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 9 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_18.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 10 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_26.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 11 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_23.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 12 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_22.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 13 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_20.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 14 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_21.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 15 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 16 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_11.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 17 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_13.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 18 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_12.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 19 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_16.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 20 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_17.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 21 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_15.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 22 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_14.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 23 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_8.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 24 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Indexing file: images/page_9.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 25 to index.\n",
      "Index exported to .byaldi/image_index\n",
      "Index exported to .byaldi/image_index\n",
      "Top 3 results for query 'What does Item 1 part A ask?':\n",
      "Doc ID: 16, Image File: page_23.png, Score: 19.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 2, Image File: page_10.png, Score: 19.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 15, Image File: page_22.png, Score: 18.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from byaldi import RAGMultiModalModel\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Initialize the ColPali model and index the images\n",
    "def initialize_model_and_index(image_directory, index_name=\"image_index\"):\n",
    "    # Initialize the model\n",
    "    model = RAGMultiModalModel.from_pretrained(\"vidore/colpali\")\n",
    "\n",
    "    # Store a mapping between Doc ID and image filename\n",
    "    doc_id_to_image = {}\n",
    "\n",
    "    # Index the images and track the Doc ID\n",
    "    model.index(\n",
    "        input_path=image_directory,\n",
    "        index_name=index_name,\n",
    "        store_collection_with_index=False,\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    # Assuming the model has a way to provide document IDs after indexing\n",
    "    # If not, use the natural order of the files as a starting point\n",
    "    image_files = sorted(os.listdir(image_directory))  # Sort to ensure matching order\n",
    "\n",
    "    for idx, image_file in enumerate(image_files):\n",
    "        doc_id_to_image[idx + 1] = image_file  # Map the index (or doc_id) to the filename\n",
    "\n",
    "    # Save the mapping for later use\n",
    "    return model, doc_id_to_image\n",
    "\n",
    "# Search for images using the mapping\n",
    "def search_and_display_images(model, doc_id_to_image, query, image_directory, top_k=3):\n",
    "    # Perform the search\n",
    "    results = model.search(query, k=top_k)\n",
    "\n",
    "    print(f\"Top {top_k} results for query '{query}':\")\n",
    "    for result in results:\n",
    "        doc_id = result.doc_id\n",
    "        page = result.page_num\n",
    "        score = result.score\n",
    "        \n",
    "        # Use the doc_id to find the corresponding image file\n",
    "        if doc_id in doc_id_to_image:\n",
    "            image_file = doc_id_to_image[doc_id]\n",
    "            image_path = os.path.join(image_directory, image_file)\n",
    "\n",
    "            # Display the search result details\n",
    "            print(f\"Doc ID: {doc_id}, Image File: {image_file}, Score: {score}\")\n",
    "\n",
    "            # Load and display the image\n",
    "            image = Image.open(image_path)\n",
    "            image.show()\n",
    "        else:\n",
    "            print(f\"Image for Doc ID {doc_id} not found.\")\n",
    "\n",
    "# Example usage:\n",
    "image_directory = \"images/\"\n",
    "model, doc_id_to_image = initialize_model_and_index(image_directory, \"image_index\")\n",
    "search_and_display_images(model, doc_id_to_image, \"What does Item 1 part A ask?\", image_directory, top_k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results for query 'Advisory Affiliates':\n",
      "Doc ID: 9, Image File: page_17.png, Score: 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 11, Image File: page_19.png, Score: 14.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 12, Image File: page_2.png, Score: 14.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "search_and_display_images(model, doc_id_to_image, \"Advisory Affiliates\", image_directory, top_k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 2/2 [01:41<00:00, 50.75s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  7.11it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from colpali_engine.models.paligemma_colbert_architecture import ColPali\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "# Initialize the ColPali model and processor\n",
    "def initialize_colpali_model():\n",
    "    model_name = \"vidore/colpali-v1.2\"\n",
    "    \n",
    "    # Load the base model and adapter for ColPali\n",
    "    model = ColPali.from_pretrained(\"vidore/colpaligemma-3b-pt-448-base\").eval()\n",
    "    model.load_adapter(model_name)\n",
    "    model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Move to GPU/CPU\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(model_name)\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "# Example usage:\n",
    "model, processor = initialize_colpali_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitajha/miniconda3/envs/localgpt-vision/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.90s/it]\n",
      "Indexing images:   0%|          | 0/26 [00:00<?, ?it/s]You are using PaliGemma without a text prefix. It will perform as a picture-captioning model.\n",
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Indexing images:   4%|▍         | 1/26 [00:30<12:39, 30.37s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:   8%|▊         | 2/26 [01:25<18:00, 45.04s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  12%|█▏        | 3/26 [02:08<16:56, 44.19s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  15%|█▌        | 4/26 [02:59<17:03, 46.54s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  19%|█▉        | 5/26 [03:42<15:54, 45.45s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  23%|██▎       | 6/26 [04:40<16:35, 49.76s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  27%|██▋       | 7/26 [05:03<12:57, 40.92s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  31%|███       | 8/26 [05:35<11:24, 38.01s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  35%|███▍      | 9/26 [06:15<10:59, 38.78s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  38%|███▊      | 10/26 [06:36<08:54, 33.41s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  42%|████▏     | 11/26 [06:56<07:18, 29.24s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  46%|████▌     | 12/26 [07:16<06:08, 26.33s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  50%|█████     | 13/26 [07:36<05:15, 24.28s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  54%|█████▍    | 14/26 [07:53<04:27, 22.31s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  58%|█████▊    | 15/26 [08:14<03:58, 21.69s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  62%|██████▏   | 16/26 [08:35<03:35, 21.53s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  65%|██████▌   | 17/26 [08:56<03:13, 21.51s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  69%|██████▉   | 18/26 [09:28<03:16, 24.56s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  73%|███████▎  | 19/26 [10:18<03:46, 32.40s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  77%|███████▋  | 20/26 [10:52<03:16, 32.69s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  81%|████████  | 21/26 [11:43<03:11, 38.33s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  85%|████████▍ | 22/26 [12:35<02:49, 42.27s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  88%|████████▊ | 23/26 [13:23<02:12, 44.02s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  92%|█████████▏| 24/26 [14:14<01:32, 46.23s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images:  96%|█████████▌| 25/26 [15:03<00:46, 46.88s/it]You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n",
      "Indexing images: 100%|██████████| 26/26 [15:25<00:00, 35.59s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from colpali_engine.models.paligemma_colbert_architecture import ColPali\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "# Initialize the ColPali model and processor\n",
    "def initialize_colpali_model():\n",
    "    model_name = \"vidore/colpali-v1.2\"\n",
    "    \n",
    "    # Load the base model and adapter for ColPali\n",
    "    model = ColPali.from_pretrained(\"vidore/colpaligemma-3b-pt-448-base\", torch_dtype=torch.float32).eval()\n",
    "    model.load_adapter(model_name)\n",
    "    model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Move to GPU/CPU\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(model_name)\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "# Example usage:\n",
    "model, processor = initialize_colpali_model()\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Generate embeddings for images using ColPali and map them to the corresponding image files\n",
    "def index_images(image_directory, model, processor):\n",
    "    image_embeddings = {}\n",
    "    doc_id_to_image = {}\n",
    "\n",
    "    # Get all image files in the directory\n",
    "    image_files = sorted(os.listdir(image_directory))\n",
    "\n",
    "    # Index each image\n",
    "    for idx, image_file in enumerate(tqdm(image_files, desc=\"Indexing images\")):\n",
    "        image_path = os.path.join(image_directory, image_file)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Preprocess the image and generate embeddings\n",
    "        inputs = processor(images=[image], return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        with torch.no_grad():\n",
    "            embedding = model(**inputs).cpu().numpy()  # Get embeddings as float32 tensor\n",
    "\n",
    "        # Store the embedding and map it to the image\n",
    "        doc_id = idx + 1\n",
    "        image_embeddings[doc_id] = embedding\n",
    "        doc_id_to_image[doc_id] = image_file\n",
    "\n",
    "    return image_embeddings, doc_id_to_image\n",
    "\n",
    "# Example usage\n",
    "image_directory = \"images/\"  # Replace with your actual image directory\n",
    "image_embeddings, doc_id_to_image = index_images(image_directory, model, processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Reduce the dimensionality of all image embeddings using PCA\n",
    "def reduce_image_embedding_dimensionality(image_embeddings, target_dim=26):\n",
    "    # Stack all the image embeddings into a matrix of shape (n_images, embedding_dim)\n",
    "    all_embeddings = np.vstack([embedding.reshape(1, -1) for embedding in image_embeddings.values()])\n",
    "    \n",
    "    # Apply PCA to reduce the dimensionality to target_dim (maximum is 26 in this case)\n",
    "    pca = PCA(n_components=target_dim)\n",
    "    reduced_embeddings = pca.fit_transform(all_embeddings)  # Reduce dimensions\n",
    "    \n",
    "    # Create a mapping of reduced embeddings back to their document IDs\n",
    "    reduced_image_embeddings = {doc_id: reduced_embedding for doc_id, reduced_embedding in zip(image_embeddings.keys(), reduced_embeddings)}\n",
    "    \n",
    "    return reduced_image_embeddings\n",
    "\n",
    "# Apply PCA to reduce image embedding dimensions to 26\n",
    "reduced_image_embeddings = reduce_image_embedding_dimensionality(image_embeddings, target_dim=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ColPali' from 'colpali_engine.models' (/Users/nikitajha/miniconda3/envs/localgpt-vision/lib/python3.10/site-packages/colpali_engine/models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbyaldi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RAGMultiModalModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Qwen2VLForConditionalGeneration,AutoTokenizer, AutoProcessor\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqwen_vl_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process_vision_info\n",
      "File \u001b[0;32m~/miniconda3/envs/localgpt-vision/lib/python3.10/site-packages/byaldi/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mRAGModel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RAGMultiModalModel\n\u001b[1;32m      5\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mByaldi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRAGMultiModalModel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/localgpt-vision/lib/python3.10/site-packages/byaldi/RAGModel.py:6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional, Union\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbyaldi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolpali\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColPaliModel\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbyaldi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobjects\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Result\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Optional langchain integration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/localgpt-vision/lib/python3.10/site-packages/byaldi/colpali.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrsly\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcolpali_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColPali, ColPaliProcessor, ColQwen2, ColQwen2Processor\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpdf2image\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_from_path\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ColPali' from 'colpali_engine.models' (/Users/nikitajha/miniconda3/envs/localgpt-vision/lib/python3.10/site-packages/colpali_engine/models/__init__.py)"
     ]
    }
   ],
   "source": [
    "from byaldi import RAGMultiModalModel\n",
    "from transformers import Qwen2VLForConditionalGeneration,AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch\n",
    "from pdf2image import convert_from_path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash-attn\n",
      "  Using cached flash_attn-2.6.3.tar.gz (2.6 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[20 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m fatal: not a git repository (or any of the parent directories): .git\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m torch.__version__  = 2.4.0\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m /private/var/folders/dr/13q6jns56rldkk1nfqpc25240000gn/T/pip-install-fu3oh81m/flash-attn_0ef965155c564c08a5b2b08f60032699/setup.py:95: UserWarning: flash_attn was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/dr/13q6jns56rldkk1nfqpc25240000gn/T/pip-install-fu3oh81m/flash-attn_0ef965155c564c08a5b2b08f60032699/setup.py\", line 179, in <module>\n",
      "  \u001b[31m   \u001b[0m     CUDAExtension(\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/nikitajha/miniconda3/envs/localgpt-vision/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1076, in CUDAExtension\n",
      "  \u001b[31m   \u001b[0m     library_dirs += library_paths(cuda=True)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/nikitajha/miniconda3/envs/localgpt-vision/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1207, in library_paths\n",
      "  \u001b[31m   \u001b[0m     if (not os.path.exists(_join_cuda_home(lib_dir)) and\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/nikitajha/miniconda3/envs/localgpt-vision/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 2416, in _join_cuda_home\n",
      "  \u001b[31m   \u001b[0m     raise OSError('CUDA_HOME environment variable is not set. '\n",
      "  \u001b[31m   \u001b[0m OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install flash-attn\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "localgpt-vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
